{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_Training_embeddings_using_gensim.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WGPwjhbbwPT"
      },
      "source": [
        "## Training Embeddings Using Gensim\n",
        "Word embeddings are an approach to representing text in NLP. In this notebook we will demonstrate how to train embeddings using Genism. [Gensim](https://radimrehurek.com/gensim/index.html) is an open source Python library for natural language processing, with a focus on topic modeling (explained in chapter 7)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyXXFeFZ750T",
        "outputId": "09481571-dfaf-4b7b-b5ec-fc6d61675dbd"
      },
      "source": [
        "# To install only the requirements of this notebook, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "!pip install gensim==3.6.0\n",
        "!pip install requests==2.23.0\n",
        "\n",
        "# ==========================="
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim==3.6.0 in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.6.0) (1.19.5)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihAJuneD750V"
      },
      "source": [
        "# To install the requirements for the entire chapter, uncomment the lines below and run this cell\n",
        "\n",
        "# ===========================\n",
        "\n",
        "# try :\n",
        "#     import google.colab\n",
        "#     !curl https://raw.githubusercontent.com/practical-nlp/practical-nlp/master/Ch3/ch3-requirements.txt | xargs -n 1 -L 1 pip install\n",
        "# except ModuleNotFoundError :\n",
        "#     !pip install -r \"ch3-requirements.txt\"\n",
        "\n",
        "# ==========================="
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:40.863650Z",
          "start_time": "2021-04-05T21:26:40.339123Z"
        },
        "id": "TBw9OCYcYQ_n"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:40.894143Z",
          "start_time": "2021-04-05T21:26:40.865114Z"
        },
        "id": "5qWptd54ZcfV"
      },
      "source": [
        "# define training data\n",
        "#Genism word2vec requires that a format of ‘list of lists’ be provided for training where every document contained in a list.\n",
        "#Every list contains lists of tokens of that document.\n",
        "corpus = [['dog','bites','man'], [\"man\", \"bites\" ,\"dog\"],[\"dog\",\"eats\",\"meat\"],[\"man\", \"eats\",\"food\"]]\n",
        "\n",
        "#Training the model\n",
        "model_cbow = Word2Vec(corpus, min_count=1,sg=0) #using CBOW Architecture for trainnig\n",
        "model_skipgram = Word2Vec(corpus, min_count=1,sg=1)#using skipGram Architecture for training "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QjSxefPl4mh"
      },
      "source": [
        "## Continuous Bag of Words (CBOW) \n",
        "In CBOW, the primary task is to build a language model that correctly predicts the center word given the context words in which the center word appears."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:56.724662Z",
          "start_time": "2021-04-05T21:26:56.712651Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZY8ME4lUjd",
        "outputId": "7b8bebcd-9fdb-42d2-a32c-ed64fb11b273"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(model_cbow)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(model_cbow.wv.vocab)\n",
        "print(words)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(model_cbow['dog'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n",
            "['dog', 'bites', 'man', 'eats', 'meat', 'food']\n",
            "[ 2.5211656e-03 -4.7110780e-03  2.8306653e-03  1.2988835e-03\n",
            " -2.8097455e-03  3.5701145e-03 -1.0838461e-03 -2.7250070e-03\n",
            " -8.1295683e-04  1.5667123e-03  2.4118358e-03 -4.7246739e-03\n",
            "  4.0631713e-03 -2.5763465e-03 -1.6118506e-04 -1.7885152e-03\n",
            " -4.3171244e-03 -2.2182211e-03 -7.9603918e-04 -2.0051922e-03\n",
            " -4.0520830e-03  3.5601703e-03 -4.8916014e-03  8.3168899e-04\n",
            "  1.8691848e-03 -7.2068983e-04  1.7822703e-03  4.8909439e-03\n",
            "  1.4495224e-04  7.1767234e-04  4.7240019e-04 -4.7488464e-03\n",
            "  3.2012935e-03 -2.2545501e-03  5.5779086e-04 -8.5462094e-04\n",
            " -2.0693108e-03 -3.2387851e-03 -4.7898539e-03  2.9532199e-03\n",
            " -2.6267513e-03  4.3456843e-03 -3.6019234e-03 -3.1687848e-03\n",
            " -4.4510062e-03  3.2532150e-03 -5.6775135e-04  4.9478044e-03\n",
            "  3.7174521e-03 -1.2643889e-03  4.7942945e-03  4.2697912e-04\n",
            "  3.9527160e-03  1.0574544e-06 -4.1726064e-03 -4.9871374e-03\n",
            "  4.4140723e-03 -3.0756535e-03 -6.5692631e-04  1.4224187e-03\n",
            " -3.3482790e-03 -7.5503299e-04  2.6607935e-03  4.2536319e-04\n",
            " -2.6803287e-03 -2.8118992e-04  4.6384442e-03 -1.1165573e-03\n",
            " -7.5188163e-04  8.7776553e-04 -2.2422627e-03 -3.6135935e-03\n",
            " -1.5384768e-03  1.3317144e-03 -1.4385344e-03  2.2318382e-03\n",
            " -2.6432027e-03 -2.7398622e-04 -1.9744197e-03 -2.2871925e-03\n",
            "  5.5917882e-04 -6.1914866e-04 -7.2595594e-04  4.9666516e-03\n",
            " -2.7891367e-03  5.4704654e-04 -3.7604810e-03  1.7327523e-03\n",
            "  1.5019998e-03 -1.9850212e-03 -2.5780164e-03  1.5672717e-03\n",
            "  4.8756734e-03 -3.2661748e-03  1.0153219e-03  1.7714992e-03\n",
            "  1.8529573e-03 -4.1100634e-03  4.3286928e-03 -1.6125903e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:57.420196Z",
          "start_time": "2021-04-05T21:26:57.417193Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMuHv52GeuoR",
        "outputId": "638cb7b9-7a93-4da9-c691-49d07e886419"
      },
      "source": [
        "#Compute similarity \n",
        "print(\"Similarity between eats and bites:\",model_cbow.similarity('eats', 'bites'))\n",
        "print(\"Similarity between eats and man:\",model_cbow.similarity('eats', 'man'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between eats and bites: -0.17754136\n",
            "Similarity between eats and man: 0.15367655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twhTZfPOezTU"
      },
      "source": [
        "From the above similarity scores we can conclude that eats is more similar to bites than man."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:59.635831Z",
          "start_time": "2021-04-05T21:26:59.621818Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lv0V7WofmsB",
        "outputId": "96c71e3b-9c35-4a2d-977f-b73f0d266e68"
      },
      "source": [
        "#Most similarity\n",
        "model_cbow.most_similar('meat')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bites', 0.07873993366956711),\n",
              " ('dog', 0.07166969776153564),\n",
              " ('food', 0.015941759571433067),\n",
              " ('man', -0.06099303811788559),\n",
              " ('eats', -0.12372516840696335)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:26:59.855822Z",
          "start_time": "2021-04-05T21:26:59.841810Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA783nrSalgs",
        "outputId": "5c38c595-d4d3-4564-f416-088ab80f6e45"
      },
      "source": [
        "# save model\n",
        "model_cbow.save('model_cbow.bin')\n",
        "\n",
        "# load model\n",
        "new_model_cbow = Word2Vec.load('model_cbow.bin')\n",
        "print(new_model_cbow)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deReLSI7mQyr"
      },
      "source": [
        "## SkipGram\n",
        "In skipgram, the task is to predict the context words from the center word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:00.517046Z",
          "start_time": "2021-04-05T21:27:00.508038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QtUtsLglvY0",
        "outputId": "e9108e9c-c727-42e1-a574-3cd26a64f730"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(model_skipgram)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(model_skipgram.wv.vocab)\n",
        "print(words)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(model_skipgram['dog'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n",
            "['dog', 'bites', 'man', 'eats', 'meat', 'food']\n",
            "[ 2.5211656e-03 -4.7110780e-03  2.8306653e-03  1.2988835e-03\n",
            " -2.8097455e-03  3.5701145e-03 -1.0838461e-03 -2.7250070e-03\n",
            " -8.1295683e-04  1.5667123e-03  2.4118358e-03 -4.7246739e-03\n",
            "  4.0631713e-03 -2.5763465e-03 -1.6118506e-04 -1.7885152e-03\n",
            " -4.3171244e-03 -2.2182211e-03 -7.9603918e-04 -2.0051922e-03\n",
            " -4.0520830e-03  3.5601703e-03 -4.8916014e-03  8.3168899e-04\n",
            "  1.8691848e-03 -7.2068983e-04  1.7822703e-03  4.8909439e-03\n",
            "  1.4495224e-04  7.1767234e-04  4.7240019e-04 -4.7488464e-03\n",
            "  3.2012935e-03 -2.2545501e-03  5.5779086e-04 -8.5462094e-04\n",
            " -2.0693108e-03 -3.2387851e-03 -4.7898539e-03  2.9532199e-03\n",
            " -2.6267513e-03  4.3456843e-03 -3.6019234e-03 -3.1687848e-03\n",
            " -4.4510062e-03  3.2532150e-03 -5.6775135e-04  4.9478044e-03\n",
            "  3.7174521e-03 -1.2643889e-03  4.7942945e-03  4.2697912e-04\n",
            "  3.9527160e-03  1.0574544e-06 -4.1726064e-03 -4.9871374e-03\n",
            "  4.4140723e-03 -3.0756535e-03 -6.5692631e-04  1.4224187e-03\n",
            " -3.3482790e-03 -7.5503299e-04  2.6607935e-03  4.2536319e-04\n",
            " -2.6803287e-03 -2.8118992e-04  4.6384442e-03 -1.1165573e-03\n",
            " -7.5188163e-04  8.7776553e-04 -2.2422627e-03 -3.6135935e-03\n",
            " -1.5384768e-03  1.3317144e-03 -1.4385344e-03  2.2318382e-03\n",
            " -2.6432027e-03 -2.7398622e-04 -1.9744197e-03 -2.2871925e-03\n",
            "  5.5917882e-04 -6.1914866e-04 -7.2595594e-04  4.9666516e-03\n",
            " -2.7891367e-03  5.4704654e-04 -3.7604810e-03  1.7327523e-03\n",
            "  1.5019998e-03 -1.9850212e-03 -2.5780164e-03  1.5672717e-03\n",
            "  4.8756734e-03 -3.2661748e-03  1.0153219e-03  1.7714992e-03\n",
            "  1.8529573e-03 -4.1100634e-03  4.3286928e-03 -1.6125903e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:02.660747Z",
          "start_time": "2021-04-05T21:27:02.642866Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YUsblEOfFWf",
        "outputId": "26a66cd2-3d89-4c7b-ef1b-a7f3df4e248e"
      },
      "source": [
        "#Compute similarity \n",
        "print(\"Similarity between eats and bites:\",model_skipgram.similarity('eats', 'bites'))\n",
        "print(\"Similarity between eats and man:\",model_skipgram.similarity('eats', 'man'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between eats and bites: -0.17754517\n",
            "Similarity between eats and man: 0.15367937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdXVDePKnBpv"
      },
      "source": [
        "From the above similarity scores we can conclude that eats is more similar to bites than man."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:03.419546Z",
          "start_time": "2021-04-05T21:27:03.414541Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpF4qtwpmuM3",
        "outputId": "a90d8d36-5fef-44f2-d0ad-6abce255ed11"
      },
      "source": [
        "#Most similarity\n",
        "model_skipgram.most_similar('meat')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bites', 0.0787399411201477),\n",
              " ('dog', 0.07166968286037445),\n",
              " ('food', 0.01594177447259426),\n",
              " ('man', -0.060993026942014694),\n",
              " ('eats', -0.12379160523414612)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:03.973454Z",
          "start_time": "2021-04-05T21:27:03.950433Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNDCEXRTnAnj",
        "outputId": "1109d578-1e2c-4311-8e04-35e58568aa56"
      },
      "source": [
        "# save model\n",
        "model_skipgram.save('model_skipgram.bin')\n",
        "\n",
        "# load model\n",
        "new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
        "print(new_model_skipgram)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0MiqJ_1M0mX"
      },
      "source": [
        "## Training Your Embedding on Wiki Corpus\n",
        "\n",
        "##### The corpus download page : https://dumps.wikimedia.org/enwiki/20200120/\n",
        "The entire wiki corpus as of 28/04/2020 is just over 16GB in size.\n",
        "We will take a part of this corpus due to computation constraints and train our word2vec and fasttext embeddings.\n",
        "\n",
        "The file size is 294MB so it can take a while to download.\n",
        "\n",
        "Source for code which downloads files from Google Drive: https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive/39225039#39225039"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-05T21:27:58.596845Z",
          "start_time": "2021-04-05T21:27:58.585833Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLq8kxmF750d",
        "outputId": "1b71df74-bbcf-4ff9-8e8a-5723eb68519f"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "os.makedirs('data/en', exist_ok= True)\n",
        "file_name = \"data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\"\n",
        "file_id = \"11804g0GcWnBIVDahjo5fQyc05nQLXGwF\"\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    download_file_from_google_drive(file_id, file_name)\n",
        "else:\n",
        "    print(\"file already exists, skipping download\")\n",
        "\n",
        "print(f\"File at: {file_name}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File at: data/en/enwiki-latest-pages-articles-multistream14.xml-p13159683p14324602.bz2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T08:59:17.024306Z",
          "start_time": "2021-04-03T08:59:17.022304Z"
        },
        "id": "wX1kx96JLYvt"
      },
      "source": [
        "from gensim.corpora.wikicorpus import WikiCorpus\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.fasttext import FastText\n",
        "import time"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T09:56:14.722195Z",
          "start_time": "2021-04-03T09:56:14.705177Z"
        },
        "id": "rJgsEUmRPppc"
      },
      "source": [
        "#Preparing the Training data\n",
        "wiki = WikiCorpus(file_name, lemmatize=False, dictionary={})\n",
        "sentences = list(wiki.get_texts())\n",
        "\n",
        "#if you get a memory error executing the lines above\n",
        "#comment the lines out and uncomment the lines below. \n",
        "#loading will be slower, but stable.\n",
        "# wiki = WikiCorpus(file_name, processes=4, lemmatize=False, dictionary={})\n",
        "# sentences = list(wiki.get_texts())\n",
        "\n",
        "#if you still get a memory error, try settings processes to 1 or 2 and then run it again."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsIrgt_gPQda"
      },
      "source": [
        "### Hyperparameters\n",
        "\n",
        "\n",
        "1.   sg - Selecting the training algorithm: 1 for skip-gram else its 0 for CBOW. Default is CBOW.\n",
        "2.   min_count-  Ignores all words with total frequency lower than this.<br>\n",
        "There are many more hyperparamaeters whose list can be found in the official documentation [here.](https://radimrehurek.com/gensim/models/word2vec.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:01:20.065332Z",
          "start_time": "2021-04-03T09:59:12.350872Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idmfbr_8LvoN",
        "outputId": "197ec8aa-7849-4775-8f91-7ce0d365045d"
      },
      "source": [
        "#CBOW\n",
        "start = time.time()\n",
        "word2vec_cbow = Word2Vec(sentences,min_count=10, sg=0)\n",
        "end = time.time()\n",
        "\n",
        "print(\"CBOW Model Training Complete.\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CBOW Model Training Complete.\n",
            "Time taken for training is:0.07 hrs \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:02:10.613551Z",
          "start_time": "2021-04-03T10:02:10.585535Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMdGn08-RkhM",
        "outputId": "f0072a3f-f82d-422f-e9a0-91952d3a6d49"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(word2vec_cbow)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(word2vec_cbow.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(word2vec_cbow['film'])}\")\n",
        "print(word2vec_cbow['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",word2vec_cbow.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",word2vec_cbow.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[ 2.99669266e-01 -2.30107337e-01 -2.83332348e+00  1.79103506e+00\n",
            " -2.36173677e+00  1.72570646e+00  1.64380169e+00 -1.66164470e+00\n",
            " -3.12124300e+00  3.81150126e-01  1.35081375e+00 -2.21470922e-01\n",
            "  1.52899250e-01  1.70926428e+00  1.81681314e-03 -9.03216541e-01\n",
            " -4.65534389e-01  2.37153435e+00  3.28944230e+00 -4.95558918e-01\n",
            " -5.94740689e-01 -1.57181859e+00  4.11749452e-01  1.24216557e+00\n",
            " -4.07071066e+00 -2.27307582e+00 -1.66209900e+00 -2.24222684e+00\n",
            " -1.05932796e+00  1.05019844e+00 -1.72928619e+00 -4.00999689e+00\n",
            "  1.46719182e+00 -2.24276233e+00  1.24641347e+00 -4.21524572e+00\n",
            "  9.76656258e-01  1.79963934e+00  1.48509622e+00 -4.56236362e-01\n",
            " -5.58120251e-01 -1.45934904e+00  2.32831573e+00  1.03190398e+00\n",
            "  6.54682994e-01  2.95263624e+00 -8.23639572e-01 -4.16845202e-01\n",
            "  1.64990544e+00 -8.86838377e-01 -2.78195834e+00 -5.65565884e-01\n",
            " -9.37131822e-01 -1.84206712e+00 -2.54025197e+00 -2.59079266e+00\n",
            "  3.04947972e+00  2.50614357e+00 -1.34396338e+00 -1.10412195e-01\n",
            "  1.44633248e-01  1.49436712e+00 -2.54006624e+00  8.65549624e-01\n",
            "  2.23652887e+00  1.53001559e+00  2.01494312e+00  3.58992107e-02\n",
            "  6.22256696e-01  1.00823784e+00 -1.38142657e+00 -2.27997160e+00\n",
            " -3.88184333e+00 -1.71323574e+00  2.19179511e+00 -1.16301203e+00\n",
            "  2.01094699e+00  2.23023248e+00 -2.47916889e+00 -2.68365979e+00\n",
            "  1.86766863e+00  1.41087270e+00  1.65393925e+00  1.78987586e+00\n",
            " -3.02522612e+00 -7.62253821e-01  1.23129368e+00 -2.54643726e+00\n",
            "  1.98462141e+00  4.09366941e+00 -5.82411528e-01 -6.60197318e-01\n",
            "  1.68045485e+00 -2.45697308e+00 -3.63437384e-01  1.38892472e+00\n",
            "  6.35629117e-01 -1.44658887e+00  1.53073406e+00 -1.64472818e+00]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.49768686\n",
            "Similarity between film and tiger: 0.17885588\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:02:16.109851Z",
          "start_time": "2021-04-03T10:02:15.257052Z"
        },
        "id": "rXrDOrKskcHX"
      },
      "source": [
        "# save model\n",
        "from gensim.models import Word2Vec, KeyedVectors   \n",
        "word2vec_cbow.wv.save_word2vec_format('word2vec_cbow.bin', binary=True)\n",
        "\n",
        "# load model\n",
        "# new_modelword2vec_cbow = Word2Vec.load('word2vec_cbow.bin')\n",
        "# print(word2vec_cbow)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:08:27.736688Z",
          "start_time": "2021-04-03T10:02:19.197708Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX0U0CbQOK30",
        "outputId": "a86c4a77-0c9f-464b-d283-9808fa434b72"
      },
      "source": [
        "#SkipGram\n",
        "start = time.time()\n",
        "word2vec_skipgram = Word2Vec(sentences,min_count=10, sg=1)\n",
        "end = time.time()\n",
        "\n",
        "print(\"SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SkipGram Model Training Complete\n",
            "Time taken for training is:0.20 hrs \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:09:06.406929Z",
          "start_time": "2021-04-03T10:09:06.383908Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXnY9YInSvnI",
        "outputId": "b151eb0c-2870-4df2-d38f-2cc4613d2f7b"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(word2vec_skipgram)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(word2vec_skipgram.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(word2vec_skipgram['film'])}\")\n",
        "print(word2vec_skipgram['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",word2vec_skipgram.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",word2vec_skipgram.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-0.4237168  -0.27985552 -0.25927952  0.3400125  -0.6667841   0.5012484\n",
            " -0.05727514  0.04838533  0.29251036 -0.4952073  -0.11132739 -0.06375849\n",
            " -0.10024641 -0.42574143  0.41230604  0.24994987 -0.1766596   0.2103304\n",
            " -0.36034128 -0.07717225  0.3511364  -0.3076286  -0.3552336  -0.15659297\n",
            " -0.1312314  -0.05537846  0.02508126 -0.66197944  0.02561701 -0.49367282\n",
            "  0.36917788 -0.5463784  -0.01422684 -0.03367303 -0.1291493  -0.07956319\n",
            " -0.6713077   0.46974298  0.02238307 -0.29419112 -0.18262397  0.01855985\n",
            "  0.37098563  0.15520486  0.6158194   0.14578134 -0.0547451  -0.08172174\n",
            "  0.6428707   0.69385684 -0.44253206  0.22313416 -0.602879    0.28839922\n",
            "  0.12988937 -0.07168498  0.10405575  0.0210879   0.0764401   0.52331465\n",
            " -0.09891954  0.83509344  0.24751136  0.7138662   0.22889751 -0.0279275\n",
            " -0.16131927 -0.16907     0.62423456  0.07625601 -0.6266109   0.07464166\n",
            " -0.647908    0.01609853  0.615516   -0.37575197  0.18886834  0.47542006\n",
            " -0.32108703  0.11722455  0.07091893 -0.18740237 -0.0066558  -0.3284618\n",
            " -0.40218323  0.18022484 -0.12150235  0.12267566  0.04140777  0.32418764\n",
            " -0.46062672  0.16411439  0.14221986 -0.36627144 -0.39216483 -0.12107299\n",
            " -0.34011865  0.17285857  0.29473382  0.24891974]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.6375442\n",
            "Similarity between film and tiger: 0.27470022\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:09:09.947695Z",
          "start_time": "2021-04-03T10:09:09.076901Z"
        },
        "id": "o8U7bfPSVB04"
      },
      "source": [
        "# save model\n",
        "word2vec_skipgram.wv.save_word2vec_format('word2vec_sg.bin', binary=True)\n",
        "\n",
        "# load model\n",
        "# new_model_skipgram = Word2Vec.load('model_skipgram.bin')\n",
        "# print(model_skipgram)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kExlA8kfrKml"
      },
      "source": [
        "## FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:16:31.271764Z",
          "start_time": "2021-04-03T10:09:16.592670Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPd2VhMEk8gL",
        "outputId": "e4ed35b2-4338-4341-e150-68763015d3af"
      },
      "source": [
        "#CBOW\n",
        "start = time.time()\n",
        "fasttext_cbow = FastText(sentences, sg=0, min_count=10)\n",
        "end = time.time()\n",
        "\n",
        "print(\"FastText CBOW Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText CBOW Model Training Complete\n",
            "Time taken for training is:0.23 hrs \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:16:31.287283Z",
          "start_time": "2021-04-03T10:16:31.273765Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlQFl8-Zsost",
        "outputId": "49e9cf5f-58c2-4cb6-89e1-c70eb0686c37"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(fasttext_cbow)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(fasttext_cbow.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(fasttext_cbow['film'])}\")\n",
        "print(fasttext_cbow['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",fasttext_cbow.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",fasttext_cbow.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-0.7463835   0.19996189 -0.9979853   4.532985    0.9235125   2.189045\n",
            " -0.31808636  3.3484747   2.8904202   5.01124     0.67354566 -5.330121\n",
            "  1.8081079  -0.06147059 -2.9210417   0.6564837   6.27072    -2.7427194\n",
            "  3.8220415  -2.6083946  -0.57947993  1.2608125   3.7221222   3.707661\n",
            " -1.8702508  -2.0417852  -2.6469572  -1.7629712  -6.2687297  -0.79994273\n",
            " -2.7692544  -0.12231357 -0.887583    1.3647972  -0.46990368  2.2163184\n",
            "  1.366861    4.930337   -3.1075075  -1.6002316   3.0699844   1.11122\n",
            " -6.8713775   1.8483716   0.41645643 -0.31872118  3.0096054  -5.532156\n",
            "  1.6102395   3.6963217   3.663656   -6.4579606  -3.445696    1.0995266\n",
            " -0.17502166 -3.2351615  -1.7987081   0.7715877  -6.5901     -4.052606\n",
            "  0.5506413   1.1240537  -0.9817307  -0.31660768  0.8579029  -4.9299016\n",
            " -0.46215907  0.5550937  -1.6686828  -3.7654505  -1.6888901  -3.583499\n",
            "  0.53538233  1.8650341   1.4992528  -2.3350844  -0.72052157  0.29675376\n",
            "  0.83089775  4.7392993   3.6813757  -4.458476   -1.6399952   1.5136546\n",
            "  6.0058446  -3.4515505  -1.1562546  -1.0320979   4.9725256  -2.6820443\n",
            "  2.3510482   0.08649306 -1.3958253  -1.3848797   2.1836684  -0.8967892\n",
            " -1.0972841  -1.391695   -0.34907514  2.9456055 ]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.5775347\n",
            "Similarity between film and tiger: 0.23721316\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:28:28.771383Z",
          "start_time": "2021-04-03T10:16:31.289284Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgSOxsNklAvh",
        "outputId": "07242007-88e5-47c2-dbb7-7378e91c045c"
      },
      "source": [
        "#SkipGram\n",
        "start = time.time()\n",
        "fasttext_skipgram = FastText(sentences, sg=1, min_count=10)\n",
        "end = time.time()\n",
        "\n",
        "print(\"FastText SkipGram Model Training Complete\\nTime taken for training is:{:.2f} hrs \".format((end-start)/3600.0))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText SkipGram Model Training Complete\n",
            "Time taken for training is:0.34 hrs \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T10:28:28.803412Z",
          "start_time": "2021-04-03T10:28:28.773386Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFiTAP0PsQwi",
        "outputId": "a376e4ff-bf30-4af8-e192-979ab2a09622"
      },
      "source": [
        "#Summarize the loaded model\n",
        "print(fasttext_skipgram)\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Summarize vocabulary\n",
        "words = list(fasttext_skipgram.wv.vocab)\n",
        "print(f\"Length of vocabulary: {len(words)}\")\n",
        "print(\"Printing the first 30 words.\")\n",
        "print(words[:30])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Acess vector for one word\n",
        "print(f\"Length of vector: {len(fasttext_skipgram['film'])}\")\n",
        "print(fasttext_skipgram['film'])\n",
        "print(\"-\"*30)\n",
        "\n",
        "#Compute similarity \n",
        "print(\"Similarity between film and drama:\",fasttext_skipgram.similarity('film', 'drama'))\n",
        "print(\"Similarity between film and tiger:\",fasttext_skipgram.similarity('film', 'tiger'))\n",
        "print(\"-\"*30)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText(vocab=111150, size=100, alpha=0.025)\n",
            "------------------------------\n",
            "Length of vocabulary: 111150\n",
            "Printing the first 30 words.\n",
            "['the', 'roses', 'registered', 'as', 'is', 'brisbane', 'racing', 'club', 'group', 'thoroughbred', 'horse', 'race', 'for', 'three', 'year', 'old', 'filles', 'run', 'under', 'set', 'weights', 'conditions', 'over', 'distance', 'of', 'metres', 'at', 'racecourse', 'australia', 'during']\n",
            "------------------------------\n",
            "Length of vector: 100\n",
            "[-0.34062257  0.20034881 -0.32438838  0.4757775   0.09694169  0.44387358\n",
            "  0.374473    0.07984764  0.12626715  0.14559336  0.17070621 -0.1242009\n",
            " -0.02354645  0.2784064   0.01321098  0.10675827  0.5270286   0.18560082\n",
            "  0.1947721  -0.09488335 -0.70429     0.03798589  0.36020663  0.4540548\n",
            "  0.82588804 -0.03594406 -0.7010492   0.08276882 -0.3600402  -0.09103949\n",
            " -0.20812891 -0.0266632   0.18376034 -0.03438908  0.18739544 -0.54230857\n",
            "  0.11515257 -0.76714796 -0.38413116  0.20995826  0.26379701 -0.14478317\n",
            " -0.2507331  -0.23866925 -0.08976771 -0.04520001  0.29641178 -0.01864165\n",
            " -0.3423282   0.13574615 -0.51550657  0.06460916 -0.20277704  0.63167423\n",
            "  0.11858363 -0.37470454  0.16942851 -0.2089076  -0.02568607 -0.34627503\n",
            "  0.2632271   0.22352041 -0.7899547   0.64767504  0.13887273 -0.38190958\n",
            " -0.18631777 -0.18322898 -0.31751177 -0.08308626  0.06825356  0.5401109\n",
            "  0.03384253  0.30849797  0.1353884  -0.00637501 -0.25858733 -0.10995787\n",
            " -0.36130926 -0.26093003 -0.18051757 -0.9410778  -0.3630112  -0.21754144\n",
            "  0.40985683 -0.07011902 -0.13193497 -0.04322884 -0.01041945  0.57367086\n",
            " -0.01106291 -0.02348732  0.84524894 -0.02717869 -0.0918304   0.43145362\n",
            " -0.17965347  0.39955035 -0.25133947 -0.20945397]\n",
            "------------------------------\n",
            "Similarity between film and drama: 0.64032143\n",
            "Similarity between film and tiger: 0.3475386\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oArMIJzYOmUR"
      },
      "source": [
        "#### An interesting obeseravtion if you noticed is that CBOW trains faster than SkipGram in both cases.\n",
        "We will leave it to the user to figure out why. A hint would be to refer the working of CBOW and skipgram."
      ]
    }
  ]
}