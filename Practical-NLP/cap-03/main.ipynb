{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = \"Dog bites man.\"\n",
    "d2 = \"Man bites dog.\"\n",
    "d3 = \"Dog eats meat.\"\n",
    "d4 = \"Man eats food.\"\n",
    "\n",
    "text = [d1, d2, d3, d4]\n",
    "tag = [\"D1\", \"D2\", \"D3\", \"D4\"]\n",
    "\n",
    "toy_df = pd.DataFrame({\"tags\": tag, \"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Dog bites man.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Man bites dog.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>Dog eats meat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>Man eats food.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tags            text\n",
       "0   D1  Dog bites man.\n",
       "1   D2  Man bites dog.\n",
       "2   D3  Dog eats meat.\n",
       "3   D4  Man eats food."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text: str):\n",
    "    text_cleaned = text.lower().replace(\".\", \"\")\n",
    "    return text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercased, punctuation removed, tokenized ...\n",
    "toy_df[\"text_transformed\"] = [pre_processing(text) for text in toy_df[\"text\"].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>text_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Dog bites man.</td>\n",
       "      <td>dog bites man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Man bites dog.</td>\n",
       "      <td>man bites dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>Dog eats meat.</td>\n",
       "      <td>dog eats meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>Man eats food.</td>\n",
       "      <td>man eats food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tags            text text_transformed\n",
       "0   D1  Dog bites man.    dog bites man\n",
       "1   D2  Man bites dog.    man bites dog\n",
       "2   D3  Dog eats meat.    dog eats meat\n",
       "3   D4  Man eats food.    man eats food"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'bites': 2, 'man': 3, 'eats': 4, 'meat': 5, 'food': 6}\n"
     ]
    }
   ],
   "source": [
    "# build the vocab\n",
    "vocab = {}\n",
    "count = 0\n",
    "for doc in toy_df[\"text_transformed\"]:\n",
    "    for word in doc.split():\n",
    "        if word not in vocab:\n",
    "            count = count + 1\n",
    "            vocab[word] = count\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot_vector(somestring: str):\n",
    "    onehot_encoded = []\n",
    "    for word in somestring.split():\n",
    "        temp = [0]*len(vocab) # a list of zeros of the len of the vocab\n",
    "        if word in vocab:\n",
    "            temp[vocab[word]-1] = 1  # vocab have numbers init from 1, and python from 0\n",
    "        onehot_encoded.append(temp)\n",
    "    return onehot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_df[\"one_hot_encoding\"] = [get_onehot_vector(text) for text in toy_df[\"text_transformed\"].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>text_transformed</th>\n",
       "      <th>one_hot_encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>Dog bites man.</td>\n",
       "      <td>dog bites man</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>Man bites dog.</td>\n",
       "      <td>man bites dog</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>Dog eats meat.</td>\n",
       "      <td>dog eats meat</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>Man eats food.</td>\n",
       "      <td>man eats food</td>\n",
       "      <td>[[0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tags            text text_transformed  \\\n",
       "0   D1  Dog bites man.    dog bites man   \n",
       "1   D2  Man bites dog.    man bites dog   \n",
       "2   D3  Dog eats meat.    dog eats meat   \n",
       "3   D4  Man eats food.    man eats food   \n",
       "\n",
       "                                    one_hot_encoding  \n",
       "0  [[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [0, 0...  \n",
       "1  [[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0...  \n",
       "2  [[1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0...  \n",
       "3  [[0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dog', 'bites', 'man'], ['man', 'bites', 'dog'], ['dog', 'eats', 'meat'], ['man', 'eats', 'food']]\n",
      "The data:  ['dog', 'bites', 'man', 'man', 'bites', 'dog', 'dog', 'eats', 'meat', 'man', 'eats', 'food']\n",
      "Label Encoded: [1 0 4 4 0 1 1 2 5 4 2 3]\n",
      "Onehot Encoded Matrix:\n",
      " [[0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "S1 = 'dog bites man'\n",
    "S2 = 'man bites dog'\n",
    "S3 = 'dog eats meat'\n",
    "S4 = 'man eats food'\n",
    "\n",
    "data = [S1.split(), S2.split(), S3.split(), S4.split()]\n",
    "print(data)\n",
    "values = data[0]+data[1]+data[2]+data[3]\n",
    "print(\"The data: \",values)\n",
    "\n",
    "#Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"Label Encoded:\",integer_encoded)\n",
    "\n",
    "#One-Hot Encoding\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "values_transformed = np.array(values).reshape(-1, 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(values_transformed).toarray()\n",
    "print(\"Onehot Encoded Matrix:\\n\",onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "\n",
    "bow_rep = count_vect.fit_transform(toy_df[\"text_transformed\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog bites man [[1 1 0 0 1 0]]\n",
      "man bites dog [[1 1 0 0 1 0]]\n",
      "dog eats meat [[0 1 1 0 0 1]]\n",
      "man eats food [[0 0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(bow_rep):\n",
    "    print(toy_df[\"text_transformed\"].to_list()[i], item.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "temp = count_vect.transform([\"dog and dog and dog are man\"])\n",
    "print(temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases we don't want the frequency of the word appearance, but just if it appears or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_bin = CountVectorizer(binary=True)\n",
    "bow_rep_bin = count_vect_bin.fit_transform(toy_df[\"text_transformed\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "temp = count_vect_bin.transform([\"dog and dog and dog are man\"])\n",
    "print(temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_rep = count_vect.fit_transform(toy_df[\"text_transformed\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dog': 3,\n",
       " 'bites': 0,\n",
       " 'man': 12,\n",
       " 'dog bites': 4,\n",
       " 'bites man': 2,\n",
       " 'dog bites man': 5,\n",
       " 'man bites': 13,\n",
       " 'bites dog': 1,\n",
       " 'man bites dog': 14,\n",
       " 'eats': 8,\n",
       " 'meat': 17,\n",
       " 'dog eats': 6,\n",
       " 'eats meat': 10,\n",
       " 'dog eats meat': 7,\n",
       " 'food': 11,\n",
       " 'man eats': 15,\n",
       " 'eats food': 9,\n",
       " 'man eats food': 16}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(toy_df[\"text_transformed\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.51082562, 1.22314355, 1.51082562, 1.91629073, 1.22314355,\n",
       "       1.91629073])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bites', 'dog', 'eats', 'food', 'man', 'meat'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.47380449 0.         0.         0.47380449 0.74230628]]\n"
     ]
    }
   ],
   "source": [
    "temp = tfidf.transform([\"dog and man are meat\"])\n",
    "print(temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "gn_vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "if not os.path.exists(\"GoogleNews-vectors-negative300.bin\"):\n",
    "    if not os.path.exists(\"../models/GoogleNews-vectors-negative300.bin\"):\n",
    "        #Downloading the reqired model\n",
    "        if not os.path.exists(\"../models/GoogleNews-vectors-negative300.bin.gz\"):\n",
    "            if not os.path.exists(\"GoogleNews-vectors-negative300.bin.gz\"):\n",
    "                wget.download(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\")\n",
    "            gn_vec_zip_path = \"../models/GoogleNews-vectors-negative300.bin.gz\"\n",
    "        else:\n",
    "            gn_vec_zip_path = \"../models/GoogleNews-vectors-negative300.bin.gz\"\n",
    "        #Extracting the required model\n",
    "        with gzip.open(gn_vec_zip_path, 'rb') as f_in:\n",
    "            with open(gn_vec_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    else:\n",
    "        gn_vec_path = \"../models/\" + gn_vec_path\n",
    "\n",
    "print(f\"Model at {gn_vec_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading Word2vec\n",
      "Numbers of words in the vocab: 3000000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11312/1855358616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done loading Word2vec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Numbers of words in the vocab: {len(w2v_model.key_to_index)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beautiful\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"beautiful\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "pretrainedpath = \"../../models/GoogleNews-vectors-negative300.bin.gz\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True)\n",
    "print(\"Done loading Word2vec\")\n",
    "print(f\"Numbers of words in the vocab: {len(w2v_model.key_to_index)}\")\n",
    "print(w2v_model.most_similar([\"beautiful\"]))\n",
    "w2v_model[\"beautiful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gorgeous', 0.8353005051612854),\n",
       " ('lovely', 0.8106936812400818),\n",
       " ('stunningly_beautiful', 0.7329413294792175),\n",
       " ('breathtakingly_beautiful', 0.7231340408325195),\n",
       " ('wonderful', 0.6854086518287659),\n",
       " ('fabulous', 0.6700063943862915),\n",
       " ('loveliest', 0.6612576246261597),\n",
       " ('prettiest', 0.6595001816749573),\n",
       " ('beatiful', 0.6593326330184937),\n",
       " ('magnificent', 0.6591402888298035)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar([\"beautiful\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01831055,  0.05566406, -0.01153564,  0.07275391,  0.15136719,\n",
       "       -0.06176758,  0.20605469, -0.15332031, -0.05908203,  0.22851562,\n",
       "       -0.06445312, -0.22851562, -0.09472656, -0.03344727,  0.24707031,\n",
       "        0.05541992, -0.00921631,  0.1328125 , -0.15429688,  0.08105469,\n",
       "       -0.07373047,  0.24316406,  0.12353516, -0.09277344,  0.08203125,\n",
       "        0.06494141,  0.15722656,  0.11279297, -0.0612793 , -0.296875  ,\n",
       "       -0.13378906,  0.234375  ,  0.09765625,  0.17773438,  0.06689453,\n",
       "       -0.27539062,  0.06445312, -0.13867188, -0.08886719,  0.171875  ,\n",
       "        0.07861328, -0.10058594,  0.23925781,  0.03808594,  0.18652344,\n",
       "       -0.11279297,  0.22558594,  0.10986328, -0.11865234,  0.02026367,\n",
       "        0.11376953,  0.09570312,  0.29492188,  0.08251953, -0.05444336,\n",
       "       -0.0090332 , -0.0625    , -0.17578125, -0.08154297,  0.01062012,\n",
       "       -0.04736328, -0.08544922, -0.19042969, -0.30273438,  0.07617188,\n",
       "        0.125     , -0.05932617,  0.03833008, -0.03564453,  0.2421875 ,\n",
       "        0.36132812,  0.04760742,  0.00631714, -0.03088379, -0.13964844,\n",
       "        0.22558594, -0.06298828, -0.02636719,  0.1171875 ,  0.33398438,\n",
       "       -0.07666016, -0.06689453,  0.04150391, -0.15136719, -0.22460938,\n",
       "        0.03320312, -0.15332031,  0.07128906,  0.16992188,  0.11572266,\n",
       "       -0.13085938,  0.12451172, -0.20410156,  0.04736328, -0.296875  ,\n",
       "       -0.17480469,  0.00872803, -0.04638672,  0.10791016, -0.203125  ,\n",
       "       -0.27539062,  0.2734375 ,  0.02563477, -0.11035156,  0.0625    ,\n",
       "        0.1953125 ,  0.16015625, -0.13769531, -0.09863281, -0.1953125 ,\n",
       "       -0.22851562,  0.25390625,  0.00915527, -0.03857422,  0.3984375 ,\n",
       "       -0.1796875 ,  0.03833008, -0.24804688,  0.03515625,  0.03881836,\n",
       "        0.03442383, -0.04101562,  0.20214844, -0.03015137, -0.09619141,\n",
       "        0.11669922, -0.06738281,  0.0625    ,  0.10742188,  0.25585938,\n",
       "       -0.21777344,  0.05639648, -0.0065918 ,  0.16113281,  0.11865234,\n",
       "       -0.03088379, -0.11572266,  0.02685547,  0.03100586,  0.09863281,\n",
       "        0.05883789,  0.00634766,  0.11914062,  0.07324219, -0.01586914,\n",
       "        0.18457031,  0.05322266,  0.19824219, -0.22363281, -0.25195312,\n",
       "        0.15039062,  0.22753906,  0.05737305,  0.16992188, -0.22558594,\n",
       "        0.06494141,  0.11914062, -0.06640625, -0.10449219, -0.07226562,\n",
       "       -0.16992188,  0.0625    ,  0.14648438,  0.27148438, -0.02172852,\n",
       "       -0.12695312,  0.18457031, -0.27539062, -0.36523438, -0.03491211,\n",
       "       -0.18554688,  0.23828125, -0.13867188,  0.00296021,  0.04272461,\n",
       "        0.13867188,  0.12207031,  0.05957031, -0.22167969, -0.18945312,\n",
       "       -0.23242188, -0.28710938, -0.00866699, -0.16113281, -0.24316406,\n",
       "        0.05712891, -0.06982422,  0.00053406, -0.10302734, -0.13378906,\n",
       "       -0.16113281,  0.11621094,  0.31640625, -0.02697754, -0.01574707,\n",
       "        0.11425781, -0.04174805,  0.05908203,  0.02661133, -0.08642578,\n",
       "        0.140625  ,  0.09228516, -0.25195312, -0.31445312, -0.05688477,\n",
       "        0.01031494,  0.0234375 , -0.02331543, -0.08056641,  0.01269531,\n",
       "       -0.34179688,  0.17285156, -0.16015625,  0.07763672, -0.03088379,\n",
       "        0.11962891,  0.11767578,  0.20117188, -0.01940918,  0.02172852,\n",
       "        0.23046875,  0.28125   , -0.17675781,  0.02978516,  0.08740234,\n",
       "       -0.06176758,  0.00939941, -0.09277344, -0.203125  ,  0.13085938,\n",
       "       -0.13671875, -0.00500488, -0.04296875,  0.12988281,  0.3515625 ,\n",
       "        0.0402832 , -0.12988281, -0.03173828,  0.28515625,  0.18261719,\n",
       "        0.13867188, -0.16503906, -0.26171875, -0.04345703,  0.0100708 ,\n",
       "        0.08740234,  0.00421143, -0.1328125 , -0.17578125, -0.04321289,\n",
       "       -0.015625  ,  0.16894531,  0.25      ,  0.37109375,  0.19921875,\n",
       "       -0.36132812, -0.10302734, -0.20800781, -0.20117188, -0.01519775,\n",
       "       -0.12207031, -0.12011719, -0.07421875, -0.04345703,  0.14160156,\n",
       "        0.15527344, -0.03027344, -0.09326172, -0.04589844,  0.16796875,\n",
       "       -0.03027344,  0.09179688, -0.10058594,  0.20703125,  0.11376953,\n",
       "       -0.12402344,  0.04003906,  0.06933594, -0.34570312,  0.03881836,\n",
       "        0.16210938,  0.05761719, -0.12792969, -0.05810547,  0.03857422,\n",
       "       -0.11328125, -0.1953125 , -0.28125   , -0.13183594,  0.15722656,\n",
       "       -0.09765625,  0.09619141, -0.09960938, -0.00285339, -0.03637695,\n",
       "        0.15429688,  0.06152344, -0.34570312,  0.11083984,  0.03344727],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key is the word and the array are the values\n",
    "# this array is a vector representation of beautiful\n",
    "w2v_model[\"beautiful\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68238cbedf6ae1d25174a29dd4170dba295aa8ea613e27a77673212528c59789"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('NLPPersonalStudy-APklfgYW': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
